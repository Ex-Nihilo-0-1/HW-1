{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parse\n",
    "import ID3\n",
    "import importlib\n",
    "import node\n",
    "from PrettyPrint import PrettyPrintTree\n",
    "import unit_tests\n",
    "\n",
    "train_examples = parse.parse(\"cars_train.data\")\n",
    "test_examples = parse.parse(\"cars_test.data\")\n",
    "valid_examples = parse.parse(\"cars_valid.data\")\n",
    "\n",
    "importlib.reload(ID3)\n",
    "importlib.reload(node)\n",
    "importlib.reload(unit_tests)\n",
    "\n",
    "t = ID3.ID3(train_examples, 0)\n",
    "\n",
    "pt = PrettyPrintTree(lambda x: list(x.children.values()), lambda x: (str(x.decision_label) + \"\\n\" + str(x.label) + \"\\n\" + str(list(x.children.keys()))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.8, 0.7142857142857143)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ID3.test(t, train_examples), ID3.test(t, valid_examples), ID3.test(t, test_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.81, 0.8, 0.7428571428571429)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID3.prune(t, valid_examples)\n",
    "(ID3.test(t, train_examples), ID3.test(t, valid_examples), ID3.test(t, test_examples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  0.6129032258064516\n",
      "validation accuracy:  0.6146788990825688\n",
      "test accuracy:  0.6146788990825688\n",
      "pruned tree train accuracy:  0.6129032258064516\n",
      "pruned tree validation accuracy:  0.6146788990825688\n",
      "pruned tree test accuracy:  0.6146788990825688\n",
      "no pruning test accuracy:  0.6146788990825688\n",
      "training accuracy:  0.576036866359447\n",
      "validation accuracy:  0.6697247706422018\n",
      "test accuracy:  0.6330275229357798\n",
      "pruned tree train accuracy:  0.576036866359447\n",
      "pruned tree validation accuracy:  0.6697247706422018\n",
      "pruned tree test accuracy:  0.6330275229357798\n",
      "no pruning test accuracy:  0.6330275229357798\n",
      "training accuracy:  0.631336405529954\n",
      "validation accuracy:  0.6513761467889908\n",
      "test accuracy:  0.5412844036697247\n",
      "pruned tree train accuracy:  0.631336405529954\n",
      "pruned tree validation accuracy:  0.6513761467889908\n",
      "pruned tree test accuracy:  0.5412844036697247\n",
      "no pruning test accuracy:  0.5412844036697247\n",
      "training accuracy:  0.5852534562211982\n",
      "validation accuracy:  0.6238532110091743\n",
      "test accuracy:  0.6605504587155964\n",
      "pruned tree train accuracy:  0.5852534562211982\n",
      "pruned tree validation accuracy:  0.6238532110091743\n",
      "pruned tree test accuracy:  0.6605504587155964\n",
      "no pruning test accuracy:  0.6605504587155964\n",
      "training accuracy:  0.6129032258064516\n",
      "validation accuracy:  0.6330275229357798\n",
      "test accuracy:  0.5963302752293578\n",
      "pruned tree train accuracy:  0.6129032258064516\n",
      "pruned tree validation accuracy:  0.6330275229357798\n",
      "pruned tree test accuracy:  0.5963302752293578\n",
      "no pruning test accuracy:  0.5963302752293578\n",
      "training accuracy:  0.6267281105990783\n",
      "validation accuracy:  0.5596330275229358\n",
      "test accuracy:  0.6422018348623854\n",
      "pruned tree train accuracy:  0.6267281105990783\n",
      "pruned tree validation accuracy:  0.5596330275229358\n",
      "pruned tree test accuracy:  0.6422018348623854\n",
      "no pruning test accuracy:  0.6422018348623854\n",
      "training accuracy:  0.6267281105990783\n",
      "validation accuracy:  0.6146788990825688\n",
      "test accuracy:  0.5871559633027523\n",
      "pruned tree train accuracy:  0.6267281105990783\n",
      "pruned tree validation accuracy:  0.6146788990825688\n",
      "pruned tree test accuracy:  0.5871559633027523\n",
      "no pruning test accuracy:  0.5871559633027523\n",
      "training accuracy:  0.6405529953917051\n",
      "validation accuracy:  0.5229357798165137\n",
      "test accuracy:  0.6513761467889908\n",
      "pruned tree train accuracy:  0.6405529953917051\n",
      "pruned tree validation accuracy:  0.5229357798165137\n",
      "pruned tree test accuracy:  0.6513761467889908\n",
      "no pruning test accuracy:  0.6513761467889908\n",
      "training accuracy:  0.6036866359447005\n",
      "validation accuracy:  0.5871559633027523\n",
      "test accuracy:  0.6605504587155964\n",
      "pruned tree train accuracy:  0.6036866359447005\n",
      "pruned tree validation accuracy:  0.5871559633027523\n",
      "pruned tree test accuracy:  0.6605504587155964\n",
      "no pruning test accuracy:  0.6605504587155964\n",
      "training accuracy:  0.5714285714285714\n",
      "validation accuracy:  0.6238532110091743\n",
      "test accuracy:  0.6880733944954128\n",
      "pruned tree train accuracy:  0.5714285714285714\n",
      "pruned tree validation accuracy:  0.6238532110091743\n",
      "pruned tree test accuracy:  0.6880733944954128\n",
      "no pruning test accuracy:  0.6880733944954128\n",
      "training accuracy:  0.6129032258064516\n",
      "validation accuracy:  0.6238532110091743\n",
      "test accuracy:  0.6055045871559633\n",
      "pruned tree train accuracy:  0.6129032258064516\n",
      "pruned tree validation accuracy:  0.6238532110091743\n",
      "pruned tree test accuracy:  0.6055045871559633\n",
      "no pruning test accuracy:  0.6055045871559633\n",
      "training accuracy:  0.5806451612903226\n",
      "validation accuracy:  0.6238532110091743\n",
      "test accuracy:  0.6697247706422018\n",
      "pruned tree train accuracy:  0.5806451612903226\n",
      "pruned tree validation accuracy:  0.6238532110091743\n",
      "pruned tree test accuracy:  0.6697247706422018\n",
      "no pruning test accuracy:  0.6697247706422018\n",
      "training accuracy:  0.5576036866359447\n",
      "validation accuracy:  0.7064220183486238\n",
      "test accuracy:  0.6330275229357798\n",
      "pruned tree train accuracy:  0.5576036866359447\n",
      "pruned tree validation accuracy:  0.7064220183486238\n",
      "pruned tree test accuracy:  0.6330275229357798\n",
      "no pruning test accuracy:  0.6330275229357798\n",
      "training accuracy:  0.631336405529954\n",
      "validation accuracy:  0.6055045871559633\n",
      "test accuracy:  0.5871559633027523\n",
      "pruned tree train accuracy:  0.631336405529954\n",
      "pruned tree validation accuracy:  0.6055045871559633\n",
      "pruned tree test accuracy:  0.5871559633027523\n",
      "no pruning test accuracy:  0.5871559633027523\n",
      "training accuracy:  0.6082949308755761\n",
      "validation accuracy:  0.6146788990825688\n",
      "test accuracy:  0.6238532110091743\n",
      "pruned tree train accuracy:  0.6082949308755761\n",
      "pruned tree validation accuracy:  0.6146788990825688\n",
      "pruned tree test accuracy:  0.6238532110091743\n",
      "no pruning test accuracy:  0.6238532110091743\n",
      "training accuracy:  0.6221198156682027\n",
      "validation accuracy:  0.6146788990825688\n",
      "test accuracy:  0.5963302752293578\n",
      "pruned tree train accuracy:  0.6221198156682027\n",
      "pruned tree validation accuracy:  0.6146788990825688\n",
      "pruned tree test accuracy:  0.5963302752293578\n",
      "no pruning test accuracy:  0.5963302752293578\n",
      "training accuracy:  0.5852534562211982\n",
      "validation accuracy:  0.6605504587155964\n",
      "test accuracy:  0.6238532110091743\n",
      "pruned tree train accuracy:  0.5852534562211982\n",
      "pruned tree validation accuracy:  0.6605504587155964\n",
      "pruned tree test accuracy:  0.6238532110091743\n",
      "no pruning test accuracy:  0.6238532110091743\n",
      "training accuracy:  0.5852534562211982\n",
      "validation accuracy:  0.6788990825688074\n",
      "test accuracy:  0.6055045871559633\n",
      "pruned tree train accuracy:  0.5852534562211982\n",
      "pruned tree validation accuracy:  0.6788990825688074\n",
      "pruned tree test accuracy:  0.6055045871559633\n",
      "no pruning test accuracy:  0.6055045871559633\n",
      "training accuracy:  0.5944700460829493\n",
      "validation accuracy:  0.6788990825688074\n",
      "test accuracy:  0.5871559633027523\n",
      "pruned tree train accuracy:  0.5944700460829493\n",
      "pruned tree validation accuracy:  0.6788990825688074\n",
      "pruned tree test accuracy:  0.5871559633027523\n",
      "no pruning test accuracy:  0.5871559633027523\n",
      "training accuracy:  0.5483870967741935\n",
      "validation accuracy:  0.7339449541284404\n",
      "test accuracy:  0.6238532110091743\n",
      "pruned tree train accuracy:  0.5483870967741935\n",
      "pruned tree validation accuracy:  0.7339449541284404\n",
      "pruned tree test accuracy:  0.6238532110091743\n",
      "no pruning test accuracy:  0.6238532110091743\n",
      "training accuracy:  0.6036866359447005\n",
      "validation accuracy:  0.5779816513761468\n",
      "test accuracy:  0.6697247706422018\n",
      "pruned tree train accuracy:  0.6036866359447005\n",
      "pruned tree validation accuracy:  0.5779816513761468\n",
      "pruned tree test accuracy:  0.6697247706422018\n",
      "no pruning test accuracy:  0.6697247706422018\n",
      "training accuracy:  0.5806451612903226\n",
      "validation accuracy:  0.6422018348623854\n",
      "test accuracy:  0.6513761467889908\n",
      "pruned tree train accuracy:  0.5806451612903226\n",
      "pruned tree validation accuracy:  0.6422018348623854\n",
      "pruned tree test accuracy:  0.6513761467889908\n",
      "no pruning test accuracy:  0.6513761467889908\n",
      "training accuracy:  0.5944700460829493\n",
      "validation accuracy:  0.6605504587155964\n",
      "test accuracy:  0.6055045871559633\n",
      "pruned tree train accuracy:  0.5944700460829493\n",
      "pruned tree validation accuracy:  0.6605504587155964\n",
      "pruned tree test accuracy:  0.6055045871559633\n",
      "no pruning test accuracy:  0.6055045871559633\n",
      "training accuracy:  0.5990783410138248\n",
      "validation accuracy:  0.6330275229357798\n",
      "test accuracy:  0.6238532110091743\n",
      "pruned tree train accuracy:  0.5990783410138248\n",
      "pruned tree validation accuracy:  0.6330275229357798\n",
      "pruned tree test accuracy:  0.6238532110091743\n",
      "no pruning test accuracy:  0.6238532110091743\n",
      "training accuracy:  0.631336405529954\n",
      "validation accuracy:  0.6330275229357798\n",
      "test accuracy:  0.5596330275229358\n",
      "pruned tree train accuracy:  0.631336405529954\n",
      "pruned tree validation accuracy:  0.6330275229357798\n",
      "pruned tree test accuracy:  0.5596330275229358\n",
      "no pruning test accuracy:  0.5596330275229358\n",
      "training accuracy:  0.6405529953917051\n",
      "validation accuracy:  0.5779816513761468\n",
      "test accuracy:  0.5963302752293578\n",
      "pruned tree train accuracy:  0.6405529953917051\n",
      "pruned tree validation accuracy:  0.5779816513761468\n",
      "pruned tree test accuracy:  0.5963302752293578\n",
      "no pruning test accuracy:  0.5963302752293578\n",
      "training accuracy:  0.5990783410138248\n",
      "validation accuracy:  0.6146788990825688\n",
      "test accuracy:  0.6422018348623854\n",
      "pruned tree train accuracy:  0.5990783410138248\n",
      "pruned tree validation accuracy:  0.6146788990825688\n",
      "pruned tree test accuracy:  0.6422018348623854\n",
      "no pruning test accuracy:  0.6422018348623854\n",
      "training accuracy:  0.6267281105990783\n",
      "validation accuracy:  0.5963302752293578\n",
      "test accuracy:  0.6055045871559633\n",
      "pruned tree train accuracy:  0.6267281105990783\n",
      "pruned tree validation accuracy:  0.5963302752293578\n",
      "pruned tree test accuracy:  0.6055045871559633\n",
      "no pruning test accuracy:  0.6055045871559633\n",
      "training accuracy:  0.5944700460829493\n",
      "validation accuracy:  0.6422018348623854\n",
      "test accuracy:  0.6238532110091743\n",
      "pruned tree train accuracy:  0.5944700460829493\n",
      "pruned tree validation accuracy:  0.6422018348623854\n",
      "pruned tree test accuracy:  0.6238532110091743\n",
      "no pruning test accuracy:  0.6238532110091743\n",
      "training accuracy:  0.6129032258064516\n",
      "validation accuracy:  0.6238532110091743\n",
      "test accuracy:  0.6055045871559633\n",
      "pruned tree train accuracy:  0.6129032258064516\n",
      "pruned tree validation accuracy:  0.6238532110091743\n",
      "pruned tree test accuracy:  0.6055045871559633\n",
      "no pruning test accuracy:  0.6055045871559633\n",
      "training accuracy:  0.5990783410138248\n",
      "validation accuracy:  0.6146788990825688\n",
      "test accuracy:  0.6422018348623854\n",
      "pruned tree train accuracy:  0.5990783410138248\n",
      "pruned tree validation accuracy:  0.6146788990825688\n",
      "pruned tree test accuracy:  0.6422018348623854\n",
      "no pruning test accuracy:  0.6422018348623854\n",
      "training accuracy:  0.6589861751152074\n",
      "validation accuracy:  0.6513761467889908\n",
      "test accuracy:  0.48623853211009177\n",
      "pruned tree train accuracy:  0.6589861751152074\n",
      "pruned tree validation accuracy:  0.6513761467889908\n",
      "pruned tree test accuracy:  0.48623853211009177\n",
      "no pruning test accuracy:  0.48623853211009177\n",
      "training accuracy:  0.5990783410138248\n",
      "validation accuracy:  0.6330275229357798\n",
      "test accuracy:  0.6238532110091743\n",
      "pruned tree train accuracy:  0.5990783410138248\n",
      "pruned tree validation accuracy:  0.6330275229357798\n",
      "pruned tree test accuracy:  0.6238532110091743\n",
      "no pruning test accuracy:  0.6238532110091743\n",
      "training accuracy:  0.6359447004608295\n",
      "validation accuracy:  0.5688073394495413\n",
      "test accuracy:  0.6146788990825688\n",
      "pruned tree train accuracy:  0.6359447004608295\n",
      "pruned tree validation accuracy:  0.5688073394495413\n",
      "pruned tree test accuracy:  0.6146788990825688\n",
      "no pruning test accuracy:  0.6146788990825688\n",
      "training accuracy:  0.663594470046083\n",
      "validation accuracy:  0.5779816513761468\n",
      "test accuracy:  0.5504587155963303\n",
      "pruned tree train accuracy:  0.663594470046083\n",
      "pruned tree validation accuracy:  0.5779816513761468\n",
      "pruned tree test accuracy:  0.5504587155963303\n",
      "no pruning test accuracy:  0.5504587155963303\n",
      "training accuracy:  0.6221198156682027\n",
      "validation accuracy:  0.6055045871559633\n",
      "test accuracy:  0.6055045871559633\n",
      "pruned tree train accuracy:  0.6221198156682027\n",
      "pruned tree validation accuracy:  0.6055045871559633\n",
      "pruned tree test accuracy:  0.6055045871559633\n",
      "no pruning test accuracy:  0.6055045871559633\n",
      "training accuracy:  0.6451612903225806\n",
      "validation accuracy:  0.5504587155963303\n",
      "test accuracy:  0.6146788990825688\n",
      "pruned tree train accuracy:  0.6451612903225806\n",
      "pruned tree validation accuracy:  0.5504587155963303\n",
      "pruned tree test accuracy:  0.6146788990825688\n",
      "no pruning test accuracy:  0.6146788990825688\n",
      "training accuracy:  0.6359447004608295\n",
      "validation accuracy:  0.5779816513761468\n",
      "test accuracy:  0.6055045871559633\n",
      "pruned tree train accuracy:  0.6359447004608295\n",
      "pruned tree validation accuracy:  0.5779816513761468\n",
      "pruned tree test accuracy:  0.6055045871559633\n",
      "no pruning test accuracy:  0.6055045871559633\n",
      "training accuracy:  0.6359447004608295\n",
      "validation accuracy:  0.5963302752293578\n",
      "test accuracy:  0.5871559633027523\n",
      "pruned tree train accuracy:  0.6359447004608295\n",
      "pruned tree validation accuracy:  0.5963302752293578\n",
      "pruned tree test accuracy:  0.5871559633027523\n",
      "no pruning test accuracy:  0.5871559633027523\n",
      "training accuracy:  0.5944700460829493\n",
      "validation accuracy:  0.6605504587155964\n",
      "test accuracy:  0.6055045871559633\n",
      "pruned tree train accuracy:  0.5944700460829493\n",
      "pruned tree validation accuracy:  0.6605504587155964\n",
      "pruned tree test accuracy:  0.6055045871559633\n",
      "no pruning test accuracy:  0.6055045871559633\n",
      "training accuracy:  0.5944700460829493\n",
      "validation accuracy:  0.6513761467889908\n",
      "test accuracy:  0.6146788990825688\n",
      "pruned tree train accuracy:  0.5944700460829493\n",
      "pruned tree validation accuracy:  0.6513761467889908\n",
      "pruned tree test accuracy:  0.6146788990825688\n",
      "no pruning test accuracy:  0.6146788990825688\n",
      "training accuracy:  0.6497695852534562\n",
      "validation accuracy:  0.5779816513761468\n",
      "test accuracy:  0.5779816513761468\n",
      "pruned tree train accuracy:  0.6497695852534562\n",
      "pruned tree validation accuracy:  0.5779816513761468\n",
      "pruned tree test accuracy:  0.5779816513761468\n",
      "no pruning test accuracy:  0.5779816513761468\n",
      "training accuracy:  0.6405529953917051\n",
      "validation accuracy:  0.6330275229357798\n",
      "test accuracy:  0.5412844036697247\n",
      "pruned tree train accuracy:  0.6405529953917051\n",
      "pruned tree validation accuracy:  0.6330275229357798\n",
      "pruned tree test accuracy:  0.5412844036697247\n",
      "no pruning test accuracy:  0.5412844036697247\n",
      "training accuracy:  0.5852534562211982\n",
      "validation accuracy:  0.6238532110091743\n",
      "test accuracy:  0.6605504587155964\n",
      "pruned tree train accuracy:  0.5852534562211982\n",
      "pruned tree validation accuracy:  0.6238532110091743\n",
      "pruned tree test accuracy:  0.6605504587155964\n",
      "no pruning test accuracy:  0.6605504587155964\n",
      "training accuracy:  0.6082949308755761\n",
      "validation accuracy:  0.6146788990825688\n",
      "test accuracy:  0.6238532110091743\n",
      "pruned tree train accuracy:  0.6082949308755761\n",
      "pruned tree validation accuracy:  0.6146788990825688\n",
      "pruned tree test accuracy:  0.6238532110091743\n",
      "no pruning test accuracy:  0.6238532110091743\n",
      "training accuracy:  0.5898617511520737\n",
      "validation accuracy:  0.6697247706422018\n",
      "test accuracy:  0.6055045871559633\n",
      "pruned tree train accuracy:  0.5898617511520737\n",
      "pruned tree validation accuracy:  0.6697247706422018\n",
      "pruned tree test accuracy:  0.6055045871559633\n",
      "no pruning test accuracy:  0.6055045871559633\n",
      "training accuracy:  0.6175115207373272\n",
      "validation accuracy:  0.6055045871559633\n",
      "test accuracy:  0.6146788990825688\n",
      "pruned tree train accuracy:  0.6175115207373272\n",
      "pruned tree validation accuracy:  0.6055045871559633\n",
      "pruned tree test accuracy:  0.6146788990825688\n",
      "no pruning test accuracy:  0.6146788990825688\n",
      "training accuracy:  0.6175115207373272\n",
      "validation accuracy:  0.6330275229357798\n",
      "test accuracy:  0.5871559633027523\n",
      "pruned tree train accuracy:  0.6175115207373272\n",
      "pruned tree validation accuracy:  0.6330275229357798\n",
      "pruned tree test accuracy:  0.5871559633027523\n",
      "no pruning test accuracy:  0.5871559633027523\n",
      "training accuracy:  0.6175115207373272\n",
      "validation accuracy:  0.6330275229357798\n",
      "test accuracy:  0.5871559633027523\n",
      "pruned tree train accuracy:  0.6175115207373272\n",
      "pruned tree validation accuracy:  0.6330275229357798\n",
      "pruned tree test accuracy:  0.5871559633027523\n",
      "no pruning test accuracy:  0.5871559633027523\n",
      "training accuracy:  0.6129032258064516\n",
      "validation accuracy:  0.6513761467889908\n",
      "test accuracy:  0.5779816513761468\n",
      "pruned tree train accuracy:  0.6129032258064516\n",
      "pruned tree validation accuracy:  0.6513761467889908\n",
      "pruned tree test accuracy:  0.5779816513761468\n",
      "no pruning test accuracy:  0.5779816513761468\n",
      "training accuracy:  0.5852534562211982\n",
      "validation accuracy:  0.6697247706422018\n",
      "test accuracy:  0.6146788990825688\n",
      "pruned tree train accuracy:  0.5852534562211982\n",
      "pruned tree validation accuracy:  0.6697247706422018\n",
      "pruned tree test accuracy:  0.6146788990825688\n",
      "no pruning test accuracy:  0.6146788990825688\n",
      "training accuracy:  0.6543778801843319\n",
      "validation accuracy:  0.5688073394495413\n",
      "test accuracy:  0.5779816513761468\n",
      "pruned tree train accuracy:  0.6543778801843319\n",
      "pruned tree validation accuracy:  0.5688073394495413\n",
      "pruned tree test accuracy:  0.5779816513761468\n",
      "no pruning test accuracy:  0.5779816513761468\n",
      "training accuracy:  0.6175115207373272\n",
      "validation accuracy:  0.6513761467889908\n",
      "test accuracy:  0.5688073394495413\n",
      "pruned tree train accuracy:  0.6175115207373272\n",
      "pruned tree validation accuracy:  0.6513761467889908\n",
      "pruned tree test accuracy:  0.5688073394495413\n",
      "no pruning test accuracy:  0.5688073394495413\n",
      "training accuracy:  0.631336405529954\n",
      "validation accuracy:  0.5688073394495413\n",
      "test accuracy:  0.6238532110091743\n",
      "pruned tree train accuracy:  0.631336405529954\n",
      "pruned tree validation accuracy:  0.5688073394495413\n",
      "pruned tree test accuracy:  0.6238532110091743\n",
      "no pruning test accuracy:  0.6238532110091743\n",
      "training accuracy:  0.6129032258064516\n",
      "validation accuracy:  0.5779816513761468\n",
      "test accuracy:  0.6513761467889908\n",
      "pruned tree train accuracy:  0.6129032258064516\n",
      "pruned tree validation accuracy:  0.5779816513761468\n",
      "pruned tree test accuracy:  0.6513761467889908\n",
      "no pruning test accuracy:  0.6513761467889908\n",
      "training accuracy:  0.6728110599078341\n",
      "validation accuracy:  0.5321100917431193\n",
      "test accuracy:  0.5779816513761468\n",
      "pruned tree train accuracy:  0.6728110599078341\n",
      "pruned tree validation accuracy:  0.5321100917431193\n",
      "pruned tree test accuracy:  0.5779816513761468\n",
      "no pruning test accuracy:  0.5779816513761468\n",
      "training accuracy:  0.6267281105990783\n",
      "validation accuracy:  0.6146788990825688\n",
      "test accuracy:  0.5871559633027523\n",
      "pruned tree train accuracy:  0.6267281105990783\n",
      "pruned tree validation accuracy:  0.6146788990825688\n",
      "pruned tree test accuracy:  0.5871559633027523\n",
      "no pruning test accuracy:  0.5871559633027523\n",
      "training accuracy:  0.5944700460829493\n",
      "validation accuracy:  0.6880733944954128\n",
      "test accuracy:  0.5779816513761468\n",
      "pruned tree train accuracy:  0.5944700460829493\n",
      "pruned tree validation accuracy:  0.6880733944954128\n",
      "pruned tree test accuracy:  0.5779816513761468\n",
      "no pruning test accuracy:  0.5779816513761468\n",
      "training accuracy:  0.5990783410138248\n",
      "validation accuracy:  0.6513761467889908\n",
      "test accuracy:  0.6055045871559633\n",
      "pruned tree train accuracy:  0.5990783410138248\n",
      "pruned tree validation accuracy:  0.6513761467889908\n",
      "pruned tree test accuracy:  0.6055045871559633\n",
      "no pruning test accuracy:  0.6055045871559633\n",
      "training accuracy:  0.6267281105990783\n",
      "validation accuracy:  0.5871559633027523\n",
      "test accuracy:  0.6146788990825688\n",
      "pruned tree train accuracy:  0.6267281105990783\n",
      "pruned tree validation accuracy:  0.5871559633027523\n",
      "pruned tree test accuracy:  0.6146788990825688\n",
      "no pruning test accuracy:  0.6146788990825688\n",
      "training accuracy:  0.5944700460829493\n",
      "validation accuracy:  0.6238532110091743\n",
      "test accuracy:  0.6422018348623854\n",
      "pruned tree train accuracy:  0.5944700460829493\n",
      "pruned tree validation accuracy:  0.6238532110091743\n",
      "pruned tree test accuracy:  0.6422018348623854\n",
      "no pruning test accuracy:  0.6422018348623854\n",
      "training accuracy:  0.6589861751152074\n",
      "validation accuracy:  0.5871559633027523\n",
      "test accuracy:  0.5504587155963303\n",
      "pruned tree train accuracy:  0.6589861751152074\n",
      "pruned tree validation accuracy:  0.5871559633027523\n",
      "pruned tree test accuracy:  0.5504587155963303\n",
      "no pruning test accuracy:  0.5504587155963303\n",
      "training accuracy:  0.6405529953917051\n",
      "validation accuracy:  0.5688073394495413\n",
      "test accuracy:  0.6055045871559633\n",
      "pruned tree train accuracy:  0.6405529953917051\n",
      "pruned tree validation accuracy:  0.5688073394495413\n",
      "pruned tree test accuracy:  0.6055045871559633\n",
      "no pruning test accuracy:  0.6055045871559633\n",
      "training accuracy:  0.5898617511520737\n",
      "validation accuracy:  0.6238532110091743\n",
      "test accuracy:  0.6513761467889908\n",
      "pruned tree train accuracy:  0.5898617511520737\n",
      "pruned tree validation accuracy:  0.6238532110091743\n",
      "pruned tree test accuracy:  0.6513761467889908\n",
      "no pruning test accuracy:  0.6513761467889908\n",
      "training accuracy:  0.5990783410138248\n",
      "validation accuracy:  0.5871559633027523\n",
      "test accuracy:  0.6697247706422018\n",
      "pruned tree train accuracy:  0.5990783410138248\n",
      "pruned tree validation accuracy:  0.5871559633027523\n",
      "pruned tree test accuracy:  0.6697247706422018\n",
      "no pruning test accuracy:  0.6697247706422018\n",
      "training accuracy:  0.6405529953917051\n",
      "validation accuracy:  0.6422018348623854\n",
      "test accuracy:  0.5321100917431193\n",
      "pruned tree train accuracy:  0.6405529953917051\n",
      "pruned tree validation accuracy:  0.6422018348623854\n",
      "pruned tree test accuracy:  0.5321100917431193\n",
      "no pruning test accuracy:  0.5321100917431193\n",
      "training accuracy:  0.6221198156682027\n",
      "validation accuracy:  0.6238532110091743\n",
      "test accuracy:  0.5871559633027523\n",
      "pruned tree train accuracy:  0.6221198156682027\n",
      "pruned tree validation accuracy:  0.6238532110091743\n",
      "pruned tree test accuracy:  0.5871559633027523\n",
      "no pruning test accuracy:  0.5871559633027523\n",
      "training accuracy:  0.6129032258064516\n",
      "validation accuracy:  0.6055045871559633\n",
      "test accuracy:  0.6238532110091743\n",
      "pruned tree train accuracy:  0.6129032258064516\n",
      "pruned tree validation accuracy:  0.6055045871559633\n",
      "pruned tree test accuracy:  0.6238532110091743\n",
      "no pruning test accuracy:  0.6238532110091743\n",
      "training accuracy:  0.6267281105990783\n",
      "validation accuracy:  0.6513761467889908\n",
      "test accuracy:  0.5504587155963303\n",
      "pruned tree train accuracy:  0.6267281105990783\n",
      "pruned tree validation accuracy:  0.6513761467889908\n",
      "pruned tree test accuracy:  0.5504587155963303\n",
      "no pruning test accuracy:  0.5504587155963303\n",
      "training accuracy:  0.631336405529954\n",
      "validation accuracy:  0.5779816513761468\n",
      "test accuracy:  0.6146788990825688\n",
      "pruned tree train accuracy:  0.631336405529954\n",
      "pruned tree validation accuracy:  0.5779816513761468\n",
      "pruned tree test accuracy:  0.6146788990825688\n",
      "no pruning test accuracy:  0.6146788990825688\n",
      "training accuracy:  0.5714285714285714\n",
      "validation accuracy:  0.6697247706422018\n",
      "test accuracy:  0.6422018348623854\n",
      "pruned tree train accuracy:  0.5714285714285714\n",
      "pruned tree validation accuracy:  0.6697247706422018\n",
      "pruned tree test accuracy:  0.6422018348623854\n",
      "no pruning test accuracy:  0.6422018348623854\n",
      "training accuracy:  0.6221198156682027\n",
      "validation accuracy:  0.5596330275229358\n",
      "test accuracy:  0.6513761467889908\n",
      "pruned tree train accuracy:  0.6221198156682027\n",
      "pruned tree validation accuracy:  0.5596330275229358\n",
      "pruned tree test accuracy:  0.6513761467889908\n",
      "no pruning test accuracy:  0.6513761467889908\n",
      "training accuracy:  0.6175115207373272\n",
      "validation accuracy:  0.6330275229357798\n",
      "test accuracy:  0.5871559633027523\n",
      "pruned tree train accuracy:  0.6175115207373272\n",
      "pruned tree validation accuracy:  0.6330275229357798\n",
      "pruned tree test accuracy:  0.5871559633027523\n",
      "no pruning test accuracy:  0.5871559633027523\n",
      "training accuracy:  0.6267281105990783\n",
      "validation accuracy:  0.6055045871559633\n",
      "test accuracy:  0.5963302752293578\n",
      "pruned tree train accuracy:  0.6267281105990783\n",
      "pruned tree validation accuracy:  0.6055045871559633\n",
      "pruned tree test accuracy:  0.5963302752293578\n",
      "no pruning test accuracy:  0.5963302752293578\n",
      "training accuracy:  0.5576036866359447\n",
      "validation accuracy:  0.6513761467889908\n",
      "test accuracy:  0.6880733944954128\n",
      "pruned tree train accuracy:  0.5576036866359447\n",
      "pruned tree validation accuracy:  0.6513761467889908\n",
      "pruned tree test accuracy:  0.6880733944954128\n",
      "no pruning test accuracy:  0.6880733944954128\n",
      "training accuracy:  0.5852534562211982\n",
      "validation accuracy:  0.6788990825688074\n",
      "test accuracy:  0.6055045871559633\n",
      "pruned tree train accuracy:  0.5852534562211982\n",
      "pruned tree validation accuracy:  0.6788990825688074\n",
      "pruned tree test accuracy:  0.6055045871559633\n",
      "no pruning test accuracy:  0.6055045871559633\n",
      "training accuracy:  0.6221198156682027\n",
      "validation accuracy:  0.5963302752293578\n",
      "test accuracy:  0.6146788990825688\n",
      "pruned tree train accuracy:  0.6221198156682027\n",
      "pruned tree validation accuracy:  0.5963302752293578\n",
      "pruned tree test accuracy:  0.6146788990825688\n",
      "no pruning test accuracy:  0.6146788990825688\n",
      "training accuracy:  0.6359447004608295\n",
      "validation accuracy:  0.6422018348623854\n",
      "test accuracy:  0.5412844036697247\n",
      "pruned tree train accuracy:  0.6359447004608295\n",
      "pruned tree validation accuracy:  0.6422018348623854\n",
      "pruned tree test accuracy:  0.5412844036697247\n",
      "no pruning test accuracy:  0.5412844036697247\n",
      "training accuracy:  0.5944700460829493\n",
      "validation accuracy:  0.6422018348623854\n",
      "test accuracy:  0.6238532110091743\n",
      "pruned tree train accuracy:  0.5944700460829493\n",
      "pruned tree validation accuracy:  0.6422018348623854\n",
      "pruned tree test accuracy:  0.6238532110091743\n",
      "no pruning test accuracy:  0.6238532110091743\n",
      "training accuracy:  0.5898617511520737\n",
      "validation accuracy:  0.6697247706422018\n",
      "test accuracy:  0.6055045871559633\n",
      "pruned tree train accuracy:  0.5898617511520737\n",
      "pruned tree validation accuracy:  0.6697247706422018\n",
      "pruned tree test accuracy:  0.6055045871559633\n",
      "no pruning test accuracy:  0.6055045871559633\n",
      "training accuracy:  0.5622119815668203\n",
      "validation accuracy:  0.6697247706422018\n",
      "test accuracy:  0.6605504587155964\n",
      "pruned tree train accuracy:  0.5622119815668203\n",
      "pruned tree validation accuracy:  0.6697247706422018\n",
      "pruned tree test accuracy:  0.6605504587155964\n",
      "no pruning test accuracy:  0.6605504587155964\n",
      "training accuracy:  0.6082949308755761\n",
      "validation accuracy:  0.6330275229357798\n",
      "test accuracy:  0.6055045871559633\n",
      "pruned tree train accuracy:  0.6082949308755761\n",
      "pruned tree validation accuracy:  0.6330275229357798\n",
      "pruned tree test accuracy:  0.6055045871559633\n",
      "no pruning test accuracy:  0.6055045871559633\n",
      "training accuracy:  0.5852534562211982\n",
      "validation accuracy:  0.6422018348623854\n",
      "test accuracy:  0.6422018348623854\n",
      "pruned tree train accuracy:  0.5852534562211982\n",
      "pruned tree validation accuracy:  0.6422018348623854\n",
      "pruned tree test accuracy:  0.6422018348623854\n",
      "no pruning test accuracy:  0.6422018348623854\n",
      "training accuracy:  0.6359447004608295\n",
      "validation accuracy:  0.5688073394495413\n",
      "test accuracy:  0.6146788990825688\n",
      "pruned tree train accuracy:  0.6359447004608295\n",
      "pruned tree validation accuracy:  0.5688073394495413\n",
      "pruned tree test accuracy:  0.6146788990825688\n",
      "no pruning test accuracy:  0.6146788990825688\n",
      "training accuracy:  0.6405529953917051\n",
      "validation accuracy:  0.5412844036697247\n",
      "test accuracy:  0.6330275229357798\n",
      "pruned tree train accuracy:  0.6405529953917051\n",
      "pruned tree validation accuracy:  0.5412844036697247\n",
      "pruned tree test accuracy:  0.6330275229357798\n",
      "no pruning test accuracy:  0.6330275229357798\n",
      "training accuracy:  0.6267281105990783\n",
      "validation accuracy:  0.6055045871559633\n",
      "test accuracy:  0.5963302752293578\n",
      "pruned tree train accuracy:  0.6267281105990783\n",
      "pruned tree validation accuracy:  0.6055045871559633\n",
      "pruned tree test accuracy:  0.5963302752293578\n",
      "no pruning test accuracy:  0.5963302752293578\n",
      "training accuracy:  0.5852534562211982\n",
      "validation accuracy:  0.6422018348623854\n",
      "test accuracy:  0.6422018348623854\n",
      "pruned tree train accuracy:  0.5852534562211982\n",
      "pruned tree validation accuracy:  0.6422018348623854\n",
      "pruned tree test accuracy:  0.6422018348623854\n",
      "no pruning test accuracy:  0.6422018348623854\n",
      "training accuracy:  0.5806451612903226\n",
      "validation accuracy:  0.6146788990825688\n",
      "test accuracy:  0.6788990825688074\n",
      "pruned tree train accuracy:  0.5806451612903226\n",
      "pruned tree validation accuracy:  0.6146788990825688\n",
      "pruned tree test accuracy:  0.6788990825688074\n",
      "no pruning test accuracy:  0.6788990825688074\n",
      "training accuracy:  0.5990783410138248\n",
      "validation accuracy:  0.6055045871559633\n",
      "test accuracy:  0.6513761467889908\n",
      "pruned tree train accuracy:  0.5990783410138248\n",
      "pruned tree validation accuracy:  0.6055045871559633\n",
      "pruned tree test accuracy:  0.6513761467889908\n",
      "no pruning test accuracy:  0.6513761467889908\n",
      "training accuracy:  0.576036866359447\n",
      "validation accuracy:  0.6330275229357798\n",
      "test accuracy:  0.6697247706422018\n",
      "pruned tree train accuracy:  0.576036866359447\n",
      "pruned tree validation accuracy:  0.6330275229357798\n",
      "pruned tree test accuracy:  0.6697247706422018\n",
      "no pruning test accuracy:  0.6697247706422018\n",
      "training accuracy:  0.5944700460829493\n",
      "validation accuracy:  0.6605504587155964\n",
      "test accuracy:  0.6055045871559633\n",
      "pruned tree train accuracy:  0.5944700460829493\n",
      "pruned tree validation accuracy:  0.6605504587155964\n",
      "pruned tree test accuracy:  0.6055045871559633\n",
      "no pruning test accuracy:  0.6055045871559633\n",
      "training accuracy:  0.6082949308755761\n",
      "validation accuracy:  0.5412844036697247\n",
      "test accuracy:  0.6972477064220184\n",
      "pruned tree train accuracy:  0.6082949308755761\n",
      "pruned tree validation accuracy:  0.5412844036697247\n",
      "pruned tree test accuracy:  0.6972477064220184\n",
      "no pruning test accuracy:  0.6972477064220184\n",
      "training accuracy:  0.5576036866359447\n",
      "validation accuracy:  0.6697247706422018\n",
      "test accuracy:  0.6697247706422018\n",
      "pruned tree train accuracy:  0.5576036866359447\n",
      "pruned tree validation accuracy:  0.6697247706422018\n",
      "pruned tree test accuracy:  0.6697247706422018\n",
      "no pruning test accuracy:  0.6697247706422018\n",
      "training accuracy:  0.6175115207373272\n",
      "validation accuracy:  0.6146788990825688\n",
      "test accuracy:  0.6055045871559633\n",
      "pruned tree train accuracy:  0.6175115207373272\n",
      "pruned tree validation accuracy:  0.6146788990825688\n",
      "pruned tree test accuracy:  0.6055045871559633\n",
      "no pruning test accuracy:  0.6055045871559633\n",
      "training accuracy:  0.6036866359447005\n",
      "validation accuracy:  0.6422018348623854\n",
      "test accuracy:  0.6055045871559633\n",
      "pruned tree train accuracy:  0.6036866359447005\n",
      "pruned tree validation accuracy:  0.6422018348623854\n",
      "pruned tree test accuracy:  0.6055045871559633\n",
      "no pruning test accuracy:  0.6055045871559633\n",
      "training accuracy:  0.6129032258064516\n",
      "validation accuracy:  0.6422018348623854\n",
      "test accuracy:  0.5871559633027523\n",
      "pruned tree train accuracy:  0.6129032258064516\n",
      "pruned tree validation accuracy:  0.6422018348623854\n",
      "pruned tree test accuracy:  0.5871559633027523\n",
      "no pruning test accuracy:  0.5871559633027523\n",
      "training accuracy:  0.6175115207373272\n",
      "validation accuracy:  0.5963302752293578\n",
      "test accuracy:  0.6238532110091743\n",
      "pruned tree train accuracy:  0.6175115207373272\n",
      "pruned tree validation accuracy:  0.5963302752293578\n",
      "pruned tree test accuracy:  0.6238532110091743\n",
      "no pruning test accuracy:  0.6238532110091743\n",
      "training accuracy:  0.6082949308755761\n",
      "validation accuracy:  0.6238532110091743\n",
      "test accuracy:  0.6146788990825688\n",
      "pruned tree train accuracy:  0.6082949308755761\n",
      "pruned tree validation accuracy:  0.6238532110091743\n",
      "pruned tree test accuracy:  0.6146788990825688\n",
      "no pruning test accuracy:  0.6146788990825688\n",
      "training accuracy:  0.6036866359447005\n",
      "validation accuracy:  0.6055045871559633\n",
      "test accuracy:  0.6422018348623854\n",
      "pruned tree train accuracy:  0.6036866359447005\n",
      "pruned tree validation accuracy:  0.6055045871559633\n",
      "pruned tree test accuracy:  0.6422018348623854\n",
      "no pruning test accuracy:  0.6422018348623854\n",
      "training accuracy:  0.6221198156682027\n",
      "validation accuracy:  0.6238532110091743\n",
      "test accuracy:  0.5871559633027523\n",
      "pruned tree train accuracy:  0.6221198156682027\n",
      "pruned tree validation accuracy:  0.6238532110091743\n",
      "pruned tree test accuracy:  0.5871559633027523\n",
      "no pruning test accuracy:  0.5871559633027523\n",
      "[0.6146788990825688, 0.6330275229357798, 0.5412844036697247, 0.6605504587155964, 0.5963302752293578, 0.6422018348623854, 0.5871559633027523, 0.6513761467889908, 0.6605504587155964, 0.6880733944954128, 0.6055045871559633, 0.6697247706422018, 0.6330275229357798, 0.5871559633027523, 0.6238532110091743, 0.5963302752293578, 0.6238532110091743, 0.6055045871559633, 0.5871559633027523, 0.6238532110091743, 0.6697247706422018, 0.6513761467889908, 0.6055045871559633, 0.6238532110091743, 0.5596330275229358, 0.5963302752293578, 0.6422018348623854, 0.6055045871559633, 0.6238532110091743, 0.6055045871559633, 0.6422018348623854, 0.48623853211009177, 0.6238532110091743, 0.6146788990825688, 0.5504587155963303, 0.6055045871559633, 0.6146788990825688, 0.6055045871559633, 0.5871559633027523, 0.6055045871559633, 0.6146788990825688, 0.5779816513761468, 0.5412844036697247, 0.6605504587155964, 0.6238532110091743, 0.6055045871559633, 0.6146788990825688, 0.5871559633027523, 0.5871559633027523, 0.5779816513761468, 0.6146788990825688, 0.5779816513761468, 0.5688073394495413, 0.6238532110091743, 0.6513761467889908, 0.5779816513761468, 0.5871559633027523, 0.5779816513761468, 0.6055045871559633, 0.6146788990825688, 0.6422018348623854, 0.5504587155963303, 0.6055045871559633, 0.6513761467889908, 0.6697247706422018, 0.5321100917431193, 0.5871559633027523, 0.6238532110091743, 0.5504587155963303, 0.6146788990825688, 0.6422018348623854, 0.6513761467889908, 0.5871559633027523, 0.5963302752293578, 0.6880733944954128, 0.6055045871559633, 0.6146788990825688, 0.5412844036697247, 0.6238532110091743, 0.6055045871559633, 0.6605504587155964, 0.6055045871559633, 0.6422018348623854, 0.6146788990825688, 0.6330275229357798, 0.5963302752293578, 0.6422018348623854, 0.6788990825688074, 0.6513761467889908, 0.6697247706422018, 0.6055045871559633, 0.6972477064220184, 0.6697247706422018, 0.6055045871559633, 0.6055045871559633, 0.5871559633027523, 0.6238532110091743, 0.6146788990825688, 0.6422018348623854, 0.5871559633027523]\n",
      "[0.6146788990825688, 0.6330275229357798, 0.5412844036697247, 0.6605504587155964, 0.5963302752293578, 0.6422018348623854, 0.5871559633027523, 0.6513761467889908, 0.6605504587155964, 0.6880733944954128, 0.6055045871559633, 0.6697247706422018, 0.6330275229357798, 0.5871559633027523, 0.6238532110091743, 0.5963302752293578, 0.6238532110091743, 0.6055045871559633, 0.5871559633027523, 0.6238532110091743, 0.6697247706422018, 0.6513761467889908, 0.6055045871559633, 0.6238532110091743, 0.5596330275229358, 0.5963302752293578, 0.6422018348623854, 0.6055045871559633, 0.6238532110091743, 0.6055045871559633, 0.6422018348623854, 0.48623853211009177, 0.6238532110091743, 0.6146788990825688, 0.5504587155963303, 0.6055045871559633, 0.6146788990825688, 0.6055045871559633, 0.5871559633027523, 0.6055045871559633, 0.6146788990825688, 0.5779816513761468, 0.5412844036697247, 0.6605504587155964, 0.6238532110091743, 0.6055045871559633, 0.6146788990825688, 0.5871559633027523, 0.5871559633027523, 0.5779816513761468, 0.6146788990825688, 0.5779816513761468, 0.5688073394495413, 0.6238532110091743, 0.6513761467889908, 0.5779816513761468, 0.5871559633027523, 0.5779816513761468, 0.6055045871559633, 0.6146788990825688, 0.6422018348623854, 0.5504587155963303, 0.6055045871559633, 0.6513761467889908, 0.6697247706422018, 0.5321100917431193, 0.5871559633027523, 0.6238532110091743, 0.5504587155963303, 0.6146788990825688, 0.6422018348623854, 0.6513761467889908, 0.5871559633027523, 0.5963302752293578, 0.6880733944954128, 0.6055045871559633, 0.6146788990825688, 0.5412844036697247, 0.6238532110091743, 0.6055045871559633, 0.6605504587155964, 0.6055045871559633, 0.6422018348623854, 0.6146788990825688, 0.6330275229357798, 0.5963302752293578, 0.6422018348623854, 0.6788990825688074, 0.6513761467889908, 0.6697247706422018, 0.6055045871559633, 0.6972477064220184, 0.6697247706422018, 0.6055045871559633, 0.6055045871559633, 0.5871559633027523, 0.6238532110091743, 0.6146788990825688, 0.6422018348623854, 0.5871559633027523]\n",
      "average with pruning 0.6135779816513761  without:  0.6135779816513761\n"
     ]
    }
   ],
   "source": [
    "unit_tests.testPruningOnHouseData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \u001b[100m a         \u001b[0m\n",
      "    \u001b[100m 1         \u001b[0m\n",
      "    \u001b[100m [1, 2, 3] \u001b[0m\n",
      "  ┌──────┼──────┐\n",
      "\u001b[100m None \u001b[0m \u001b[100m None \u001b[0m \u001b[100m None \u001b[0m\n",
      "\u001b[100m 1    \u001b[0m \u001b[100m 2    \u001b[0m \u001b[100m 3    \u001b[0m\n",
      "\u001b[100m []   \u001b[0m \u001b[100m []   \u001b[0m \u001b[100m []   \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data = [dict(a=1, b=0, c='?', Class=1), dict(a=1, b=3, c=2, Class=1),\n",
    "         dict(a=2, b='?', c=1, Class=2), dict(a=2, b=1, c=3, Class=2),\n",
    "         dict(a=3, b=0, c=1, Class=3), dict(a=3, b=2, c='?', Class=3)]\n",
    "t = ID3.ID3(data, 0)\n",
    "pt(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID3 test 1 succeeded.\n",
      "ID3 test 2 succeeded.\n",
      "ID3 test 3-1 succeeded.\n",
      "ID3 test 3-2 succeeded.\n",
      "ID3 test 4-1 succeeded.\n",
      "ID3 test 4-2 succeeded.\n"
     ]
    }
   ],
   "source": [
    "import mini_auto_grader as mg\n",
    "mg.mini_grader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID3 test 1 succeeded.\n",
      "ID3 test 2 succeeded.\n",
      "ID3 test 3-1 succeeded.\n",
      "ID3 test 3-2 succeeded.\n",
      "ID3 test 4-1 succeeded.\n",
      "ID3 test 4-2 succeeded.\n"
     ]
    }
   ],
   "source": [
    "import unit_tests as ut\n",
    "mg.mini_grader()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([1,2,3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
